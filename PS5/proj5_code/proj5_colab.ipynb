{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Dv8absVKufcA",
      "metadata": {
        "id": "Dv8absVKufcA"
      },
      "source": [
        "# Semantic Segmentation with Deep Learning: Training and Testing on Colab\n",
        "\n",
        "Insert the following Javascript snippet into your browser console so that your Colab runtime won't time out. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and type this on the console prompt. (for mac press Option+Command+I)\n",
        "```Javascript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdweXW5Xqd6R",
      "metadata": {
        "id": "bdweXW5Xqd6R"
      },
      "source": [
        "Zip up your code locally with `python zip_for_colab.py`, and upload your `cv_proj5.zip` file. Hit refresh, then run the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ah8PNwYTqM1G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah8PNwYTqM1G",
        "outputId": "7da69a5a-eb1c-4a2a-c9d0-8274111e13e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!unzip cv_proj5_colab.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0pf627lnqsTo",
      "metadata": {
        "id": "0pf627lnqsTo"
      },
      "source": [
        "Install the `proj6_code` module locally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "sEkEfbqNqxa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEkEfbqNqxa4",
        "outputId": "f033af2e-2ddf-4461-c1ff-f6bf9aa57123"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sensitive-franchise",
      "metadata": {
        "id": "sensitive-franchise"
      },
      "source": [
        "Download ImageNet-pretrained ResNet-50:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bound-explosion",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bound-explosion",
        "outputId": "65c88d14-ec29-46ca-8ed6-ebf37ad16bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'id' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'mv' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget -O \"resnet50_v2.pth\" --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w5pRmLJXvmQQA5PtCbHhZc_uC4o0YbmA'\n",
        "!mkdir initmodel && mv resnet50_v2.pth initmodel/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "yZDeFtlyuXNz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZDeFtlyuXNz",
        "outputId": "abe3b5b3-1bdb-45fa-9086-d17b4f66b6e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# The ImageNet-pretrained ResNet-50 weights should be 99 MB\n",
        "!ls -ltrh initmodel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7wzfFzyHupog",
      "metadata": {
        "id": "7wzfFzyHupog"
      },
      "source": [
        "Download the Camvid dataset images. It's 700 MB, but it should only take 30 sec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "intellectual-delaware",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "intellectual-delaware",
        "outputId": "d6599992-e192-41d8-a8b7-128f9d1df951"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'sed' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'.' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!chmod +rwx camvid_download_dataset.sh\n",
        "!sed -i -e 's/\\r$//' camvid_download_dataset.sh\n",
        "!./camvid_download_dataset.sh Camvid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "PGBUoTc9Aj0t",
      "metadata": {
        "id": "PGBUoTc9Aj0t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "The system cannot find the path specified.\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "!cd Camvid && unzip camvid_semseg11.zip && cd .."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "AC_-gfRptGgF",
      "metadata": {
        "id": "AC_-gfRptGgF"
      },
      "source": [
        "We'll now set some default hyperparameters for training. Choose the number of epochs you'd like to train for (for PSPNet, it will take ~30 min for 50 epochs, or ~70 min for 100 epochs). SimpleSegmentationNet will be a bit faster, but make sure to leave enough time to train both models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "absent-major",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "absent-major",
        "outputId": "89b6a608-73af-47ab-c94e-096183d89e91"
      },
      "outputs": [],
      "source": [
        "#!python --version\n",
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace(\n",
        "    **{\n",
        "        # DATA\n",
        "        \"names_path\": \"camvid_dataset_lists/camvid-11/camvid-11_names.txt\",\n",
        "        \"data_root\": \"Camvid/\",\n",
        "        \"train_list\": \"camvid_dataset_lists/camvid-11/list/train.txt\",  \n",
        "        \"val_list\": \"camvid_dataset_lists/camvid-11/list/val.txt\",\n",
        "        \"classes\": 11,\n",
        "        # TRAIN\n",
        "        \"arch\": \"SimpleSegmentationNet\", #  \"PSPNet\", # SimpleSegmentationNet\n",
        "        \"save_path\": \"\",\n",
        "        \"epochs\": 5,\n",
        "        \"zoom_factor\": 8,\n",
        "        \"use_ppm\": False,   # set to True for PSPNet\n",
        "        \"aux_weight\": 0.4,\n",
        "        \"aux_loss\": False,   # set to True for PSPNet\n",
        "        \"layers\": 50,\n",
        "        \"workers\": 2,\n",
        "        \"batch_size\": 32,\n",
        "        \"batch_size_val\": 32,\n",
        "        \"data_aug\": True,\n",
        "        \"short_size\": 240,\n",
        "        \"train_h\": 201,\n",
        "        \"train_w\": 201,\n",
        "        \"init_weight\": \"./initmodel/resnet50_v2.pth\",\n",
        "        \"scale_min\": 0.5,  # minimum random scale\n",
        "        \"scale_max\": 2.0,  # maximum random scale\n",
        "        \"rotate_min\": -10,  # minimum random rotate\n",
        "        \"rotate_max\": 10,  # maximum random rotate\n",
        "        \"ignore_label\": 255,\n",
        "        \"base_lr\": 0.01,\n",
        "        \"start_epoch\": 0,\n",
        "        \"power\": 0.9,\n",
        "        \"momentum\": 0.9,\n",
        "        \"weight_decay\": 0.0001,\n",
        "        \"manual_seed\": 0,\n",
        "        \"print_freq\": 10,\n",
        "        \"save_freq\": 1,\n",
        "        \"evaluate\": True,  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend\n",
        "        \"multiprocessing_distributed\": False,\n",
        "        # INFERENCE\n",
        "        \"dataset\": \"camvid-11\",\n",
        "        \"base_size\": 240,\n",
        "        \"test_h\": 201,\n",
        "        \"test_w\": 201,\n",
        "        \"scales\": [1.0], # [0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
        "        \"test_list\": \"camvid_dataset_lists/camvid-11/list/val.txt\",\n",
        "        \"vis_freq\": 10,\n",
        "        \"pretrained\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "args.save_path = f\"exp/camvid/{args.arch}/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "increased-blade",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "increased-blade",
        "outputId": "350cafdf-fab5-4846-c481-071291419a6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "namespace(names_path='camvid_dataset_lists/camvid-11/camvid-11_names.txt', data_root='Camvid/', train_list='camvid_dataset_lists/camvid-11/list/train.txt', val_list='camvid_dataset_lists/camvid-11/list/val.txt', classes=11, arch='SimpleSegmentationNet', save_path='exp/camvid/SimpleSegmentationNet/model', epochs=5, zoom_factor=8, use_ppm=False, aux_weight=0.4, aux_loss=False, layers=50, workers=2, batch_size=32, batch_size_val=32, data_aug=True, short_size=240, train_h=201, train_w=201, init_weight='./initmodel/resnet50_v2.pth', scale_min=0.5, scale_max=2.0, rotate_min=-10, rotate_max=10, ignore_label=255, base_lr=0.01, start_epoch=0, power=0.9, momentum=0.9, weight_decay=0.0001, manual_seed=0, print_freq=10, save_freq=1, evaluate=True, multiprocessing_distributed=False, dataset='camvid-11', base_size=240, test_h=201, test_w=201, scales=[1.0], test_list='camvid_dataset_lists/camvid-11/list/val.txt', vis_freq=10, pretrained=True)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './initmodel/resnet50_v2.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mproj5_code\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msegmentation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m main_worker\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(args)\n\u001b[1;32m----> 9\u001b[0m main_worker(args, torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_available())\n",
            "File \u001b[1;32m~\\OneDrive\\Desktop\\computer vision\\PS5\\proj5_code\\segmentation\\trainer.py:57\u001b[0m, in \u001b[0;36mmain_worker\u001b[1;34m(args, use_cuda)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain_worker\u001b[39m(args, use_cuda: \u001b[39mbool\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[39m\"\"\" \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     model, optimizer \u001b[39m=\u001b[39m get_model_and_optimizer(args)\n\u001b[0;32m     58\u001b[0m     logger\u001b[39m.\u001b[39minfo(args)\n\u001b[0;32m     59\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m=> creating model ...\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\OneDrive\\Desktop\\computer vision\\PS5\\proj5_code\\segmentation\\training_utils.py:46\u001b[0m, in \u001b[0;36mget_model_and_optimizer\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     44\u001b[0m         modules_new \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39mcls, model\u001b[39m.\u001b[39maux]\n\u001b[0;32m     45\u001b[0m \u001b[39melif\u001b[39;00m args\u001b[39m.\u001b[39march \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSimpleSegmentationNet\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 46\u001b[0m     model \u001b[39m=\u001b[39m SimpleSegmentationNet(pretrained\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mpretrained, num_classes\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mclasses, criterion\u001b[39m=\u001b[39;49mcriterion)\n\u001b[0;32m     47\u001b[0m     modules_orig \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39mlayer0, model\u001b[39m.\u001b[39mresnet\u001b[39m.\u001b[39mlayer1, model\u001b[39m.\u001b[39mresnet\u001b[39m.\u001b[39mlayer2, model\u001b[39m.\u001b[39mresnet\u001b[39m.\u001b[39mlayer3, model\u001b[39m.\u001b[39mresnet\u001b[39m.\u001b[39mlayer4]\n\u001b[0;32m     48\u001b[0m     modules_new \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39mcls]\n",
            "File \u001b[1;32m~\\OneDrive\\Desktop\\computer vision\\PS5\\proj5_code\\segmentation\\simple_segmentation_net.py:29\u001b[0m, in \u001b[0;36mSimpleSegmentationNet.__init__\u001b[1;34m(self, pretrained, num_classes, criterion, deep_base)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m=\u001b[39m criterion\n\u001b[0;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeep_base \u001b[39m=\u001b[39m deep_base\n\u001b[1;32m---> 29\u001b[0m resnet \u001b[39m=\u001b[39m resnet50(pretrained\u001b[39m=\u001b[39;49mpretrained, deep_base\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresnet \u001b[39m=\u001b[39m resnet\n\u001b[0;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer0 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     32\u001b[0m     resnet\u001b[39m.\u001b[39mconv1,\n\u001b[0;32m     33\u001b[0m     resnet\u001b[39m.\u001b[39mbn1,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     resnet\u001b[39m.\u001b[39mmaxpool,\n\u001b[0;32m     42\u001b[0m )\n",
            "File \u001b[1;32m~\\OneDrive\\Desktop\\computer vision\\PS5\\proj5_code\\segmentation\\resnet.py:181\u001b[0m, in \u001b[0;36mresnet50\u001b[1;34m(pretrained, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m pretrained:\n\u001b[0;32m    179\u001b[0m     \u001b[39m# model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     model_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./initmodel/resnet50_v2.pth\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 181\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(model_path), strict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[1;32mc:\\Users\\wiley\\Anaconda3\\envs\\proj5\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[1;32mc:\\Users\\wiley\\Anaconda3\\envs\\proj5\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
            "File \u001b[1;32mc:\\Users\\wiley\\Anaconda3\\envs\\proj5\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './initmodel/resnet50_v2.pth'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "os.makedirs(args.save_path, exist_ok=True)\n",
        "from proj5_code.segmentation.trainer import main_worker\n",
        "print(args)\n",
        "main_worker(args, torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7or_wjTqvX6H",
      "metadata": {
        "id": "7or_wjTqvX6H"
      },
      "source": [
        "We'll now create full-resolution predictions for the full val set, and compute mIoU against the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worst-vegetation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worst-vegetation",
        "outputId": "374e92e9-64fb-46cc-a950-9a0d653fd303"
      },
      "outputs": [],
      "source": [
        "from proj5_code.segmentation.test import test_model\n",
        "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n",
        "test_model(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ETWCIkf1vfCP",
      "metadata": {
        "id": "ETWCIkf1vfCP"
      },
      "source": [
        "**Important**: Record the mIoU listed in the output above, and the IoU per each class. You can find the results later in `train_epoch_{args.epochs}/camvid-11/240/results.txt`.\n",
        "\n",
        "Now, let's take a look at what our results look like. We'll make a 2x3 image grid with the following structure:\n",
        "\n",
        "|RGB Image | Blended RGB and Ground Truth | Ground Truth \n",
        "|:-: | :-: | :-:\n",
        "| RGB Image | Blended RGB and Prediction | Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cDpIrDQvvBq5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "cDpIrDQvvBq5",
        "outputId": "779e4804-4ce0-4007-f82f-4454bfbcd174"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rgb_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/rgb_mask_predictions\"\n",
        "\n",
        "def show_image_grid(rgb_predictions_dir: str, img_fname: str) -> None:\n",
        "  img_grid = imageio.imread(f'{rgb_predictions_dir}/{img_fname}')\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.imshow(img_grid)\n",
        "  plt.show()\n",
        "\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_07977.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JOxOOpJ-wDHa",
      "metadata": {
        "id": "JOxOOpJ-wDHa"
      },
      "source": [
        "We'll look at more examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wJo0THuZvDkU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wJo0THuZvDkU",
        "outputId": "61716e00-32ab-408b-a005-4426dbc26d28"
      },
      "outputs": [],
      "source": [
        "show_image_grid(rgb_predictions_dir, \"0016E5_07997.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08017.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08037.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08057.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08077.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08097.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08117.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08137.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08157.jpg\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "VFCSB5B23t19",
      "metadata": {
        "id": "VFCSB5B23t19"
      },
      "source": [
        "Now, zip up your predictions on the test set for your best SimpleSegmentationNet model, **download them locally to your machine**, and submit these to Gradescope :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VbYbqcNn3eS2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbYbqcNn3eS2",
        "outputId": "abd55052-5551-4636-f762-719696ff9224"
      },
      "outputs": [],
      "source": [
        "grayscale_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/gray\"\n",
        "!ls -ltrh $grayscale_predictions_dir\n",
        "!zip -r grayscale_predictions.zip $grayscale_predictions_dir\n",
        "!ls -ltrh grayscale_predictions.zip"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
